{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfafd34",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:09.032770Z",
     "iopub.status.busy": "2023-12-04T12:37:09.032241Z",
     "iopub.status.idle": "2023-12-04T12:37:09.886694Z",
     "shell.execute_reply": "2023-12-04T12:37:09.885867Z"
    },
    "papermill": {
     "duration": 0.866869,
     "end_time": "2023-12-04T12:37:09.888993",
     "exception": false,
     "start_time": "2023-12-04T12:37:09.022124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/argugpt/argugpt.csv\n",
      "/kaggle/input/argugpt/machine-dev.csv\n",
      "/kaggle/input/argugpt/machine-test.csv\n",
      "/kaggle/input/argugpt/machine-train.csv\n",
      "/kaggle/input/d/leesyyyy/models2/vocab.spm\n",
      "/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n",
      "/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n",
      "/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n",
      "/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n",
      "/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\n",
      "/kaggle/input/daigt-proper-train-dataset/train_drcat_03.csv\n",
      "/kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv\n",
      "/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\n",
      "/kaggle/input/daigt-proper-train-dataset/train_drcat_01.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6baa3b98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:09.907440Z",
     "iopub.status.busy": "2023-12-04T12:37:09.907089Z",
     "iopub.status.idle": "2023-12-04T12:37:28.057125Z",
     "shell.execute_reply": "2023-12-04T12:37:28.056286Z"
    },
    "papermill": {
     "duration": 18.161564,
     "end_time": "2023-12-04T12:37:28.059382",
     "exception": false,
     "start_time": "2023-12-04T12:37:09.897818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import keras_nlp\n",
    "import keras_core as keras\n",
    "import keras_core.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac37917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:28.078713Z",
     "iopub.status.busy": "2023-12-04T12:37:28.078192Z",
     "iopub.status.idle": "2023-12-04T12:37:35.643573Z",
     "shell.execute_reply": "2023-12-04T12:37:35.642622Z"
    },
    "papermill": {
     "duration": 7.576931,
     "end_time": "2023-12-04T12:37:35.645500",
     "exception": false,
     "start_time": "2023-12-04T12:37:28.068569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7c74fd09b610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9f6362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:35.664625Z",
     "iopub.status.busy": "2023-12-04T12:37:35.664307Z",
     "iopub.status.idle": "2023-12-04T12:37:35.794794Z",
     "shell.execute_reply": "2023-12-04T12:37:35.793862Z"
    },
    "papermill": {
     "duration": 0.142147,
     "end_time": "2023-12-04T12:37:35.796869",
     "exception": false,
     "start_time": "2023-12-04T12:37:35.654722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>ff669174</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0</td>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n",
       "1375  ffa247e0          0  There's a new trend that has been developing f...   \n",
       "1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n",
       "1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n",
       "\n",
       "      generated  label  \n",
       "0             0      0  \n",
       "1             0      0  \n",
       "2             0      0  \n",
       "3             0      0  \n",
       "4             0      0  \n",
       "...         ...    ...  \n",
       "1373          0      0  \n",
       "1374          0      0  \n",
       "1375          0      0  \n",
       "1376          0      0  \n",
       "1377          0      0  \n",
       "\n",
       "[1378 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\n",
    "train_data['label'] = train_data.generated.copy()\n",
    "# print(set(train_data['source']))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a12200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:35.816207Z",
     "iopub.status.busy": "2023-12-04T12:37:35.815919Z",
     "iopub.status.idle": "2023-12-04T12:37:35.825411Z",
     "shell.execute_reply": "2023-12-04T12:37:35.824589Z"
    },
    "papermill": {
     "duration": 0.021204,
     "end_time": "2023-12-04T12:37:35.827267",
     "exception": false,
     "start_time": "2023-12-04T12:37:35.806063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5b6baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:35.846392Z",
     "iopub.status.busy": "2023-12-04T12:37:35.846124Z",
     "iopub.status.idle": "2023-12-04T12:37:37.963752Z",
     "shell.execute_reply": "2023-12-04T12:37:37.962756Z"
    },
    "papermill": {
     "duration": 2.130272,
     "end_time": "2023-12-04T12:37:37.966634",
     "exception": false,
     "start_time": "2023-12-04T12:37:35.836362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kingki19_palm', 'darragh_claude_v7', 'chat_gpt_moth', 'llama_70b_v1', 'mistralai/Mistral-7B-Instruct-v0.1', 'darragh_claude_v6', 'radek_500', 'train_essays', 'llama2_chat', 'palm-text-bison1', 'cohere-command', 'falcon_180b_v1', 'radekgpt4', 'mistral7binstruct_v2', 'persuade_corpus', 'mistral7binstruct_v1', 'NousResearch/Llama-2-7b-chat-hf'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44863</th>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>kingki19_palm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44864</th>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>kingki19_palm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44865</th>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>kingki19_palm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44866</th>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>kingki19_palm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44867</th>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>kingki19_palm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44868 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      Phones\\n\\nModern humans today are always on th...      0   \n",
       "1      This essay will explain if drivers should or s...      0   \n",
       "2      Driving while the use of cellular devices\\n\\nT...      0   \n",
       "3      Phones & Driving\\n\\nDrivers should not be able...      0   \n",
       "4      Cell Phone Operation While Driving\\n\\nThe abil...      0   \n",
       "...                                                  ...    ...   \n",
       "44863  Dear Senator,\\n\\nI am writing to you today to ...      1   \n",
       "44864  Dear Senator,\\n\\nI am writing to you today to ...      1   \n",
       "44865  Dear Senator,\\n\\nI am writing to you today to ...      1   \n",
       "44866  Dear Senator,\\n\\nI am writing to you today to ...      1   \n",
       "44867  Dear Senator,\\n\\nI am writing to you today to ...      1   \n",
       "\n",
       "                            prompt_name           source  RDizzl3_seven  \n",
       "0                    Phones and driving  persuade_corpus          False  \n",
       "1                    Phones and driving  persuade_corpus          False  \n",
       "2                    Phones and driving  persuade_corpus          False  \n",
       "3                    Phones and driving  persuade_corpus          False  \n",
       "4                    Phones and driving  persuade_corpus          False  \n",
       "...                                 ...              ...            ...  \n",
       "44863  Does the electoral college work?    kingki19_palm           True  \n",
       "44864  Does the electoral college work?    kingki19_palm           True  \n",
       "44865  Does the electoral college work?    kingki19_palm           True  \n",
       "44866  Does the electoral college work?    kingki19_palm           True  \n",
       "44867  Does the electoral college work?    kingki19_palm           True  \n",
       "\n",
       "[44868 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')\n",
    "print(set(train_data['source']))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a29e256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:37.994320Z",
     "iopub.status.busy": "2023-12-04T12:37:37.993468Z",
     "iopub.status.idle": "2023-12-04T12:37:38.069859Z",
     "shell.execute_reply": "2023-12-04T12:37:38.069018Z"
    },
    "papermill": {
     "duration": 0.091088,
     "end_time": "2023-12-04T12:37:38.071864",
     "exception": false,
     "start_time": "2023-12-04T12:37:37.980776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.concat([\n",
    "    train_data[train_data.label==0].groupby('prompt_name',group_keys=False)\n",
    "    .apply(lambda group: group.sample(frac=17497/len(train_data[train_data.label==0]), random_state=42)),\n",
    "    train_data[train_data.label==1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58bf94da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:38.091928Z",
     "iopub.status.busy": "2023-12-04T12:37:38.091636Z",
     "iopub.status.idle": "2023-12-04T12:37:38.130860Z",
     "shell.execute_reply": "2023-12-04T12:37:38.129501Z"
    },
    "papermill": {
     "duration": 0.051481,
     "end_time": "2023-12-04T12:37:38.132849",
     "exception": false,
     "start_time": "2023-12-04T12:37:38.081368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17498\n",
      "17497\n",
      "34995\n",
      "비율 맞춤\n",
      "prompt_name\n",
      "Does the electoral college work?         1735\n",
      "Car-free cities                          1704\n",
      "Facial action coding system              1385\n",
      "Distance learning                        1379\n",
      "Driverless cars                          1206\n",
      "Exploring Venus                          1190\n",
      "Summer projects                          1119\n",
      "Mandatory extracurricular activities     1068\n",
      "Cell phones at school                    1059\n",
      "Grades for extracurricular activities    1039\n",
      "The Face on Mars                         1012\n",
      "Seeking multiple opinions                 992\n",
      "Community service                         986\n",
      "\"A Cowboy Who Rode the Waves\"             877\n",
      "Phones and driving                        747\n",
      "dtype: int64\n",
      "17498\n",
      "\n",
      "원래 데이터\n",
      "prompt_name\n",
      "Does the electoral college work?         2714\n",
      "Car-free cities                          2666\n",
      "Facial action coding system              2167\n",
      "Distance learning                        2157\n",
      "Driverless cars                          1886\n",
      "Exploring Venus                          1862\n",
      "Summer projects                          1750\n",
      "Mandatory extracurricular activities     1670\n",
      "Cell phones at school                    1656\n",
      "Grades for extracurricular activities    1626\n",
      "The Face on Mars                         1583\n",
      "Seeking multiple opinions                1552\n",
      "Community service                        1542\n",
      "\"A Cowboy Who Rode the Waves\"            1372\n",
      "Phones and driving                       1168\n",
      "dtype: int64\n",
      "27371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/1604050160.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(train[train_data.label == 0].groupby('prompt_name').size().sort_values(ascending=False))\n",
      "/tmp/ipykernel_26/1604050160.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(sum(train[train_data.label == 0].groupby('prompt_name').size()))\n"
     ]
    }
   ],
   "source": [
    "print(sum(train['label']==0))\n",
    "print(sum(train['label']==1))\n",
    "print(len(train))\n",
    "print('비율 맞춤')\n",
    "print(train[train_data.label == 0].groupby('prompt_name').size().sort_values(ascending=False))\n",
    "print(sum(train[train_data.label == 0].groupby('prompt_name').size()))\n",
    "print()\n",
    "# print(sum(train['prompt_name'].value_counts()))\n",
    "print('원래 데이터')\n",
    "print(train_data[train_data.label == 0].groupby('prompt_name').size().sort_values(ascending=False))\n",
    "print(sum(train_data[train_data.label == 0].groupby('prompt_name').size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dd005b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:38.153056Z",
     "iopub.status.busy": "2023-12-04T12:37:38.152798Z",
     "iopub.status.idle": "2023-12-04T12:37:38.166290Z",
     "shell.execute_reply": "2023-12-04T12:37:38.165452Z"
    },
    "papermill": {
     "duration": 0.026054,
     "end_time": "2023-12-04T12:37:38.168393",
     "exception": false,
     "start_time": "2023-12-04T12:37:38.142339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17498\n",
      "17497\n",
      "34995\n"
     ]
    }
   ],
   "source": [
    "print(sum(train['label']==0))\n",
    "print(sum(train['label']==1))\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c322918a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:38.189063Z",
     "iopub.status.busy": "2023-12-04T12:37:38.188795Z",
     "iopub.status.idle": "2023-12-04T12:37:38.192639Z",
     "shell.execute_reply": "2023-12-04T12:37:38.191813Z"
    },
    "papermill": {
     "duration": 0.016175,
     "end_time": "2023-12-04T12:37:38.194463",
     "exception": false,
     "start_time": "2023-12-04T12:37:38.178288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=6\n",
    "num_folds=5\n",
    "epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c573060b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:38.214843Z",
     "iopub.status.busy": "2023-12-04T12:37:38.214533Z",
     "iopub.status.idle": "2023-12-04T12:37:39.131940Z",
     "shell.execute_reply": "2023-12-04T12:37:39.130807Z"
    },
    "papermill": {
     "duration": 0.92984,
     "end_time": "2023-12-04T12:37:39.134061",
     "exception": false,
     "start_time": "2023-12-04T12:37:38.204221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold  label  source                            \n",
       "0     0      persuade_corpus                       3329\n",
       "             train_essays                           171\n",
       "      1      NousResearch/Llama-2-7b-chat-hf         80\n",
       "             chat_gpt_moth                          484\n",
       "             cohere-command                          70\n",
       "                                                   ... \n",
       "4     1      mistralai/Mistral-7B-Instruct-v0.1      80\n",
       "             palm-text-bison1                        70\n",
       "             radek_500                              100\n",
       "             radekgpt4                               40\n",
       "             train_essays                             1\n",
       "Length: 88, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "train = train.reset_index(drop=True) \n",
    "train['stratify'] = train.label.astype(str)+ train.source.astype(str)\n",
    "train[\"fold\"]=-1\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['stratify'])):\n",
    "    train.loc[val_idx, 'fold'] = fold\n",
    "  \n",
    "train.groupby([\"fold\", \"label\",\"source\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414ed54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:39.156218Z",
     "iopub.status.busy": "2023-12-04T12:37:39.155911Z",
     "iopub.status.idle": "2023-12-04T12:37:39.896986Z",
     "shell.execute_reply": "2023-12-04T12:37:39.896197Z"
    },
    "papermill": {
     "duration": 0.754817,
     "end_time": "2023-12-04T12:37:39.899222",
     "exception": false,
     "start_time": "2023-12-04T12:37:39.144405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from keras_nlp.models import DebertaV3Preprocessor\n",
    "\n",
    "# SentencePiece 모델 파일 경로 설정\n",
    "proto = '/kaggle/input/d/leesyyyy/models2/vocab.spm'\n",
    "tokenizer = keras_nlp.models.DebertaV3Tokenizer(proto)\n",
    "\n",
    "# 전처리 클래스 생성\n",
    "preprocessor = DebertaV3Preprocessor(\n",
    "    tokenizer,  # 모델 이름\n",
    "    sequence_length=200    # 최대 시퀀스 길이 (짧은 경우 패딩)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1483db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:39.920837Z",
     "iopub.status.busy": "2023-12-04T12:37:39.920478Z",
     "iopub.status.idle": "2023-12-04T12:37:40.096040Z",
     "shell.execute_reply": "2023-12-04T12:37:40.095023Z"
    },
    "papermill": {
     "duration": 0.188794,
     "end_time": "2023-12-04T12:37:40.098150",
     "exception": false,
     "start_time": "2023-12-04T12:37:39.909356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids : torch.Size([200])\n",
      "padding_mask : torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "inp = preprocessor(train.text.iloc[0])  # Process text for the first row\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in inp.items():\n",
    "    print(k, \":\", v.shape)\n",
    "    \n",
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b047261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.121190Z",
     "iopub.status.busy": "2023-12-04T12:37:40.120875Z",
     "iopub.status.idle": "2023-12-04T12:37:40.128302Z",
     "shell.execute_reply": "2023-12-04T12:37:40.127564Z"
    },
    "papermill": {
     "duration": 0.020297,
     "end_time": "2023-12-04T12:37:40.130202",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.109905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=False, drop_remainder=True,\n",
    "                  repeat=False, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, labels)  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
    "    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=42)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds  # Return the built dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68c96f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.151494Z",
     "iopub.status.busy": "2023-12-04T12:37:40.151216Z",
     "iopub.status.idle": "2023-12-04T12:37:40.158006Z",
     "shell.execute_reply": "2023-12-04T12:37:40.157163Z"
    },
    "papermill": {
     "duration": 0.0198,
     "end_time": "2023-12-04T12:37:40.159932",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.140132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datasets(fold):\n",
    "    # Split the dataset into train and validation sets\n",
    "    train_df = train[train.fold!=fold].sample(frac=1)\n",
    "    \n",
    "    # Get training data for the specified fold\n",
    "    train_texts = train_df.text.tolist()\n",
    "    train_labels = train_df.label.tolist()\n",
    "\n",
    "    # Build training dataset\n",
    "    train_ds = build_dataset(train_texts, train_labels,\n",
    "                             batch_size=batch_size, cache=False,\n",
    "                             shuffle=True, drop_remainder=True, repeat=True)\n",
    "\n",
    "    # Get validation data for the specified fold\n",
    "    valid_df = train[train.fold==fold].sample(frac=1)\n",
    "    valid_texts = valid_df.text.tolist()\n",
    "    valid_labels = valid_df.label.tolist()\n",
    "\n",
    "    # Build validation dataset\n",
    "    valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                             batch_size=min(batch_size, len(valid_df)), cache=False,\n",
    "                             shuffle=False, drop_remainder=True, repeat=False)\n",
    "\n",
    "    return (train_ds, train_df), (valid_ds, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91b54584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.181343Z",
     "iopub.status.busy": "2023-12-04T12:37:40.181059Z",
     "iopub.status.idle": "2023-12-04T12:37:40.185868Z",
     "shell.execute_reply": "2023-12-04T12:37:40.185084Z"
    },
    "papermill": {
     "duration": 0.017416,
     "end_time": "2023-12-04T12:37:40.187735",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.170319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_callbacks(fold):\n",
    "    callbacks = []\n",
    "    ckpt_cb = keras.callbacks.ModelCheckpoint(f'fold{fold}.keras',\n",
    "                                              monitor='val_auc',\n",
    "                                              save_best_only=True,\n",
    "                                              save_weights_only=False,\n",
    "                                              mode='max')  # Get Model checkpoint callback\n",
    "    callbacks.append(ckpt_cb)  # Add checkpoint callback        \n",
    "    return callbacks  # Return the list of callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22842e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.208466Z",
     "iopub.status.busy": "2023-12-04T12:37:40.208201Z",
     "iopub.status.idle": "2023-12-04T12:37:40.379826Z",
     "shell.execute_reply": "2023-12-04T12:37:40.378944Z"
    },
    "papermill": {
     "duration": 0.184335,
     "end_time": "2023-12-04T12:37:40.381967",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.197632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone = keras_nlp.models.DebertaV3Backbone(\n",
    "    vocabulary_size=30552,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    hidden_dim=256,\n",
    "    intermediate_dim=512,\n",
    "    max_sequence_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c6ba94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.402878Z",
     "iopub.status.busy": "2023-12-04T12:37:40.402589Z",
     "iopub.status.idle": "2023-12-04T12:37:40.410624Z",
     "shell.execute_reply": "2023-12-04T12:37:40.409701Z"
    },
    "papermill": {
     "duration": 0.020592,
     "end_time": "2023-12-04T12:37:40.412449",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.391857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras_nlp.models import DebertaV3Classifier\n",
    "def build_model():\n",
    "    # Create a DebertaV3Classifier model\n",
    "    backbone = keras_nlp.models.DebertaV3Backbone(\n",
    "    vocabulary_size=128100,\n",
    "    num_layers=12,\n",
    "    num_heads=12,\n",
    "    hidden_dim=768,\n",
    "    intermediate_dim=3072,\n",
    "    max_sequence_length=512,\n",
    "    )\n",
    "    \n",
    "    classifier = DebertaV3Classifier(\n",
    "        backbone,\n",
    "        preprocessor=None,\n",
    "        num_classes=1  # one output per one option, for five options total 5 outputs\n",
    "    )\n",
    "    inputs = classifier.input\n",
    "    logits = classifier(inputs)\n",
    "\n",
    "    # Compute final output\n",
    "    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "    # Use the learning rate schedule in the optimizer\n",
    "\n",
    "    # Compile the model with optimizer, loss, and metrics\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.AdamW(5e-6),\n",
    "        loss=keras.losses.BinaryCrossentropy(label_smoothing=0.02),\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\"),\n",
    "        ],\n",
    "        jit_compile=True\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d87d14aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.433572Z",
     "iopub.status.busy": "2023-12-04T12:37:40.433302Z",
     "iopub.status.idle": "2023-12-04T12:37:40.815639Z",
     "shell.execute_reply": "2023-12-04T12:37:40.814684Z"
    },
    "papermill": {
     "duration": 0.395248,
     "end_time": "2023-12-04T12:37:40.817897",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.422649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras_core/src/trainers/trainer.py:166: UserWarning: `jit_compile` is not yet enabled for the PyTorch backend. Proceeding with `jit_compile=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b7e1b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.841001Z",
     "iopub.status.busy": "2023-12-04T12:37:40.840710Z",
     "iopub.status.idle": "2023-12-04T12:37:40.864966Z",
     "shell.execute_reply": "2023-12-04T12:37:40.864155Z"
    },
    "papermill": {
     "duration": 0.037914,
     "end_time": "2023-12-04T12:37:40.866885",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.828971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\"> Param # </span>┃<span style=\"font-weight: bold\"> Connected to         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ deberta_v3_classif… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">184,42…</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DebertaV3Classifi…</span> │                   │         │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ deberta_v3_classifi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │         │                      │\n",
       "└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mParam #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │       \u001b[38;5;34m0\u001b[0m │ -                    │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │       \u001b[38;5;34m0\u001b[0m │ -                    │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ deberta_v3_classif… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │ \u001b[38;5;34m184,42…\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mDebertaV3Classifi…\u001b[0m │                   │         │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │       \u001b[38;5;34m0\u001b[0m │ deberta_v3_classifi… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │         │                      │\n",
       "└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">184,422,913</span> (703.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m184,422,913\u001b[0m (703.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">184,422,913</span> (703.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m184,422,913\u001b[0m (703.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb3f426b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T12:37:40.890053Z",
     "iopub.status.busy": "2023-12-04T12:37:40.889793Z",
     "iopub.status.idle": "2023-12-04T14:33:45.956724Z",
     "shell.execute_reply": "2023-12-04T14:33:45.955322Z"
    },
    "papermill": {
     "duration": 6966.209367,
     "end_time": "2023-12-04T14:33:47.087273",
     "exception": false,
     "start_time": "2023-12-04T12:37:40.877906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\tFold: 2 | Model: deberta_v3_base_en\n",
      "\tBatch Size: 6\n",
      "\tNum Train: 27996 | Num Valid: 6999\n",
      "--------------------------------------------------\n",
      "Epoch 1/3\n",
      "\u001b[1m4666/4666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2319s\u001b[0m 496ms/step - auc: 0.9481 - loss: 0.2655 - val_auc: 0.9985 - val_loss: 0.0970\n",
      "Epoch 2/3\n",
      "\u001b[1m4666/4666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2322s\u001b[0m 498ms/step - auc: 0.9974 - loss: 0.0964 - val_auc: 0.9988 - val_loss: 0.0812\n",
      "Epoch 3/3\n",
      "\u001b[1m4666/4666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2315s\u001b[0m 496ms/step - auc: 0.9985 - loss: 0.0800 - val_auc: 0.9990 - val_loss: 0.0754\n",
      "\n",
      "================= FOLD 2 RESULTS =================\n",
      ">>>> BEST Loss  : 0.075\n",
      ">>>> BEST AUC   : 0.999\n",
      ">>>> BEST Epoch : 2\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for fold in range(2,3):\n",
    "    (train_ds, train_df), (valid_ds, valid_df) = get_datasets(fold)\n",
    "    callbacks = get_callbacks(fold)\n",
    "    print('-' * 50)\n",
    "    print(f'\\tFold: {fold} | Model: deberta_v3_base_en\\n\\tBatch Size: {batch_size}')\n",
    "    print(f'\\tNum Train: {len(train_df)} | Num Valid: {len(valid_df)}')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Clear TensorFlow session and build the model within the strategy scope\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = build_model()\n",
    "        \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=int(len(train_df) / batch_size),\n",
    "    )\n",
    "    \n",
    "    best_epoch = np.argmax(model.history.history['val_auc'])\n",
    "    best_auc = model.history.history['val_auc'][best_epoch]\n",
    "    best_loss = model.history.history['val_loss'][best_epoch]\n",
    "    \n",
    "     # Print and display best results\n",
    "    print(f'\\n{\"=\" * 17} FOLD {fold} RESULTS {\"=\" * 17}')\n",
    "    print(f'>>>> BEST Loss  : {best_loss:.3f}\\n>>>> BEST AUC   : {best_auc:.3f}\\n>>>> BEST Epoch : {best_epoch}')\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff5083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T15:44:35.781573Z",
     "iopub.status.busy": "2023-11-28T15:44:35.781119Z",
     "iopub.status.idle": "2023-11-28T15:44:35.786788Z",
     "shell.execute_reply": "2023-11-28T15:44:35.785684Z",
     "shell.execute_reply.started": "2023-11-28T15:44:35.781535Z"
    },
    "papermill": {
     "duration": 1.151765,
     "end_time": "2023-12-04T14:33:49.545009",
     "exception": false,
     "start_time": "2023-12-04T14:33:48.393244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21b66d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T14:33:51.921601Z",
     "iopub.status.busy": "2023-12-04T14:33:51.920918Z",
     "iopub.status.idle": "2023-12-04T14:33:51.946730Z",
     "shell.execute_reply": "2023-12-04T14:33:51.945684Z"
    },
    "papermill": {
     "duration": 1.190583,
     "end_time": "2023-12-04T14:33:51.948677",
     "exception": false,
     "start_time": "2023-12-04T14:33:50.758094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaa bbb ccc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>3</td>\n",
       "      <td>Bbb ccc ddd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>4</td>\n",
       "      <td>CCC ddd eee.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id          text\n",
       "0  0000aaaa          2  Aaa bbb ccc.\n",
       "1  1111bbbb          3  Bbb ccc ddd.\n",
       "2  2222cccc          4  CCC ddd eee."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n",
    "test=pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83eb4259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T14:33:57.131227Z",
     "iopub.status.busy": "2023-12-04T14:33:57.130718Z",
     "iopub.status.idle": "2023-12-04T14:33:57.969356Z",
     "shell.execute_reply": "2023-12-04T14:33:57.968317Z"
    },
    "papermill": {
     "duration": 1.996325,
     "end_time": "2023-12-04T14:33:57.971473",
     "exception": false,
     "start_time": "2023-12-04T14:33:55.975148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids : (3, 200)\n",
      "padding_mask : (3, 200)\n"
     ]
    }
   ],
   "source": [
    "test_texts = test['text'].tolist()\n",
    "\n",
    "# Build test dataset\n",
    "test_ds = build_dataset(test_texts,\n",
    "                        batch_size=batch_size, cache=False,\n",
    "                        shuffle=False, drop_remainder=False, repeat=False)\n",
    "\n",
    "# Display the shape of each processed output for the first sample\n",
    "for sample in test_ds.take(1):\n",
    "    for k, v in sample.items():\n",
    "        print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c87b1853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T14:34:00.339820Z",
     "iopub.status.busy": "2023-12-04T14:34:00.339163Z",
     "iopub.status.idle": "2023-12-04T14:34:00.666286Z",
     "shell.execute_reply": "2023-12-04T14:34:00.665386Z"
    },
    "papermill": {
     "duration": 1.485765,
     "end_time": "2023-12-04T14:34:00.668169",
     "exception": false,
     "start_time": "2023-12-04T14:33:59.182404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_ds,batch_size=batch_size,verbose=1)\n",
    "# predictions = model.predict(\n",
    "#     valid_ds,\n",
    "#     batch_size=min(CFG.batch_size * CFG.replicas * 2, len(valid_df)), # max batch size = valid size\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185dafa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T14:34:03.040165Z",
     "iopub.status.busy": "2023-12-04T14:34:03.039722Z",
     "iopub.status.idle": "2023-12-04T14:34:03.050737Z",
     "shell.execute_reply": "2023-12-04T14:34:03.049842Z"
    },
    "papermill": {
     "duration": 1.228933,
     "end_time": "2023-12-04T14:34:03.052787",
     "exception": false,
     "start_time": "2023-12-04T14:34:01.823854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.437792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.009741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.991403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.437792\n",
       "1  1111bbbb   0.009741\n",
       "2  2222cccc   0.991403"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 결과 출력\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'generated': predictions.flatten()\n",
    "})\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92e856eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T14:34:05.388053Z",
     "iopub.status.busy": "2023-12-04T14:34:05.387333Z",
     "iopub.status.idle": "2023-12-04T14:34:05.394521Z",
     "shell.execute_reply": "2023-12-04T14:34:05.393773Z"
    },
    "papermill": {
     "duration": 1.210034,
     "end_time": "2023-12-04T14:34:05.396737",
     "exception": false,
     "start_time": "2023-12-04T14:34:04.186703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312be74",
   "metadata": {
    "papermill": {
     "duration": 1.214237,
     "end_time": "2023-12-04T14:34:07.790817",
     "exception": false,
     "start_time": "2023-12-04T14:34:06.576580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52e7dd",
   "metadata": {
    "papermill": {
     "duration": 1.205602,
     "end_time": "2023-12-04T14:34:10.172250",
     "exception": false,
     "start_time": "2023-12-04T14:34:08.966648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5d973",
   "metadata": {
    "papermill": {
     "duration": 1.214053,
     "end_time": "2023-12-04T14:34:12.583680",
     "exception": false,
     "start_time": "2023-12-04T14:34:11.369627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45ffce",
   "metadata": {
    "papermill": {
     "duration": 1.187824,
     "end_time": "2023-12-04T14:34:14.925495",
     "exception": false,
     "start_time": "2023-12-04T14:34:13.737671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e085f6",
   "metadata": {
    "papermill": {
     "duration": 1.197755,
     "end_time": "2023-12-04T14:34:17.253008",
     "exception": false,
     "start_time": "2023-12-04T14:34:16.055253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d04c67",
   "metadata": {
    "papermill": {
     "duration": 1.127076,
     "end_time": "2023-12-04T14:34:19.529809",
     "exception": false,
     "start_time": "2023-12-04T14:34:18.402733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3946973,
     "sourceId": 6867914,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3942644,
     "sourceId": 6890527,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4055480,
     "sourceId": 7047560,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4060913,
     "sourceId": 7055363,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4065190,
     "sourceId": 7061304,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7038.799741,
   "end_time": "2023-12-04T14:34:24.263714",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-04T12:37:05.463973",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
